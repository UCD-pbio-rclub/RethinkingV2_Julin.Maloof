---
title: "Chapter 7"
output: 
  html_document: 
    keep_md: yes
---

```{r}
library(tidyverse)
library(rethinking)
```
## Problems

### 6E1. 
_State the three motivating criteria that define information entropy. Try to express each in your own words._

Entropy is a measure of uncertainity.  We want any measure of uncertainity to be:

* Continuous, so that changes in parameters or distributions do not cause unessecarily large changes in our measure.
* Increase as the number of possible outcomes increases.  If more things can happen, then there is less certainity about what will happen.
* Need to be additive, so that we can combine multiple events.


### 6E2. 
_Suppose a coin is weighted such that, when it is tossed and lands on a table, it comes up heads 70% of the time. What is the entropy of this coin?_

```{r}
p <- c(.7, .3)
-sum(p*log(p))
```


### 6E3. 
_Suppose a four-sided die is loaded such that, when tossed onto a table, it shows “1” 20%, “2” 25%, ”3” 25%, and ”4” 30% of the time. What is the entropy of this die?_

```{r}
p <- c(.2, .25, .25, .3)
sum(p)
-sum(p*log(p))
```

### 6E4. 
_Suppose another four-sided die is loaded such that it never shows “4”. The other three sides show equally often. What is the entropy of this die?_

```{r}
p <- c(1/3, 1/3, 1/3)
sum(p)
-sum(p*log(p))
```

### 6M1. 
_Write down and compare the definitions of AIC, DIC, and WAIC. Which of these criteria is most general? Which assumptions are required to transform a more general criterion into a less general one?_

These are all ways of approximating out-of-sample deviance.  
__AIC__

$$
-2*lppd + 2*p
$$
Assumes: 
* Flat priors (or priors overwhelmed by observations)
* Observations >> parameters
* Gaussian posterior


__DIC__
DIC not really discussed in this version of the book, however:

Assumes: 
* Observations >> parameters
* Gaussian posterior

__WAIC__

$$
-2*lppd + 2*pWAIC
$$

$$
pWAIC = \sum(Var(lppd))
$$
Assumes: 
* ?? Observations >> parameters ??


### 6M2. 
_Explain the difference between model selection and model averaging. What information is lost under model selection? What information is lost under model averaging?_

model selection: pick the best model by some criteria.  model averaging: average across multiple models, weighted by some criteria.

in selection, we lose information from what is still a well-supported model and thus are ignoring some uncertainity.

in averaging we may lose out ability to make the best possible predictions?

### 6M3. 
_When comparing models with an information criterion, why must all models be fit to exactly the same observations? What would happen to the information criterion values, if the models were fit to different numbers of observations? Perform some experiments, if you are not sure._

Because we are summing log probabilities across observations, more observations (with the same model) will always lead to higher deviance / lower lppd. 

### 6M4. 
_What happens to the effective number of parameters, as measured by DIC or WAIC, as a prior becomes more concentrated? Why? Perform some experiments, if you are not sure._

The effective number of paramters will decrease

### 6M5. 
_Provide an informal explanation of why informative priors reduce overfitting._

informative priors require more evidence to push a coefficient away from zero.

### 6M6. 
_Provide an information explanation of why overly informative priors result in underfitting_

If too informative, the priors can overwhelm the evidence and force coefficients to remain near 0

### 1: Birbs
```{r}
birbs <- tibble(
  Birb=LETTERS[1:5],
  Island1=rep(0.2,5),
  Island2=c(.8,.1,.05,.025,.025),
  Island3=c(0.05,0.15,0.7,0.05,0.05))
birbs
```

```{r}
entropy <- function(x) {
  -sum(x*log(x))
}
(island_entropies <- apply(birbs[,-1],2,entropy))
```

There is the highest entropy, that is the highest uncertainity about which birb you might see, on Island 1

```{r}
KLdivergence <- function(pname,qname, data=birbs) {
  print(cat("pname",pname))
  p=get(pname, data)
  q=get(qname, data)
  -sum(p*log(p/q))  # where p is the true distribution and q is what we are using to predict
}

Islands <- colnames(birbs)[-1]

results.frame <- expand.grid(predictor_q=Islands,
                             predictee_p=Islands,stringsAsFactors = FALSE) %>% as_tibble()

results.frame <- results.frame %>%
  mutate(KLdiv = map2_dbl(predictee_p, predictor_q, ~ KLdivergence(.x, .y)))

results.frame %>% filter(KLdiv!=0) %>% arrange(predictee_p, desc(KLdiv))
```

For each case, the island with the higher entropy is the better predictor, because it is less likely to be surprised

### 2
_Recall the marriage, age, and happiness collider bias example from Chapter 6. Run models m6.9 and m6.10 again. Compare these two models using WAIC (or LOO, they will produce identical results). Which model is expected to make better predictions? Which model provides the correct causal inference about the influence of age on happiness? Can you explain why the answers to these two questions disagree?_

```{r}
## R code 6.22
library(rethinking)
d <- sim_happiness( seed=1977 , N_years=1000 )
precis(d)

## R code 6.23
d2 <- d[ d$age>17 , ] # only adults
d2$A <- ( d2$age - 18 ) / ( 65 - 18 )
```


```{r}
## R code 6.24
d2$mid <- d2$married + 1
m6.9 <- quap(
    alist(
        happiness ~ dnorm( mu , sigma ),
        mu <- a[mid] + bA*A,
        a[mid] ~ dnorm( 0 , 1 ),
        bA ~ dnorm( 0 , 2 ),
        sigma ~ dexp(1)
    ) , data=d2 )
precis(m6.9,depth=2)

## R code 6.25
m6.10 <- quap(
    alist(
        happiness ~ dnorm( mu , sigma ),
        mu <- a + bA*A,
        a ~ dnorm( 0 , 1 ),
        bA ~ dnorm( 0 , 2 ),
        sigma ~ dexp(1)
    ) , data=d2 )
precis(m6.10)
```

```{r}
plot(coeftab(m6.9, m6.10))
```


```{r}
compare(m6.9, m6.10)
```

model 6.9 is best by WAIC.  This is because the generative model has marriage as a collider, so marriage relates happiness to age.

### 3
_Reconsider the urban fox analysis from last week’s homework. Use WAIC or LOO based model comparison on five different models, each using weight as the outcome, and containing these sets of predictor variables:_
(1) avgfood + groupsize + area
(2) avgfood + groupsize
(3) groupsize + area
(4) avgfood
(5) area
_Can you explain the relative differences in WAIC scores, using the fox DAG from last week’s homework? Be sure to pay attention to the standard error of the score differences (dSE)._

```{r}
library(dagitty)
foxdag <- dagitty("dag {
area -> avgfood
avgfood -> groupsize
avgfood -> weight
groupsize -> weight
}")

coordinates(foxdag) <- list(
  x=c(area=1, avgfood=0, groupsize=2, weight=1),
  y=c(area=0, avgfood=1, groupsize=1, weight=2))

plot(foxdag)
```


```{r}
data("foxes")
head(foxes)
```

```{r}
foxes2 <- foxes %>%
  mutate_at(vars(-group), scale)
head(foxes2)
```

models
```{r}
m1 <- quap(alist(
  weight ~ dnorm(mu, sigma),
  mu <- alpha + bF*avgfood + bG*groupsize + bA*area,
  alpha ~ dnorm(0,.2),
  bF ~ dnorm(0,.5),
  bG ~ dnorm(0,.5),
  bA ~ dnorm(0,.5),
  sigma ~ dexp(1)),
  data=foxes2)

m2 <- quap(alist(
  weight ~ dnorm(mu, sigma),
  mu <- alpha + bF*avgfood + bG*groupsize,
  alpha ~ dnorm(0,.2),
  bF ~ dnorm(0,.5),
  bG ~ dnorm(0,.5),
  sigma ~ dexp(1)),
  data=foxes2)

m3 <- quap(alist(
  weight ~ dnorm(mu, sigma),
  mu <- alpha + bG*groupsize + bA*area,
  alpha ~ dnorm(0,.2),
  bG ~ dnorm(0,.5),
  bA ~ dnorm(0,.5),
  sigma ~ dexp(1)),
  data=foxes2)

m4 <- quap(alist(
  weight ~ dnorm(mu, sigma),
  mu <- alpha + bF*avgfood,
  alpha ~ dnorm(0,.2),
  bF ~ dnorm(0,.5),
  sigma ~ dexp(1)),
  data=foxes2)

m5 <- quap(alist(
  weight ~ dnorm(mu, sigma),
  mu <- alpha + bA*area,
  alpha ~ dnorm(0,.2),
  bA ~ dnorm(0,.5),
  sigma ~ dexp(1)),
  data=foxes2)
```

```{r}
compare(m1, m2, m3, m4, m5)
```

m1,2,3 are equivalent by weight.  Arguallably all the models are the same.

I can't really explain this.  I would have that that 2 would be better than 1, for example since 2 is simple and area doesn't have a direct impact on weight...

## Code from Book

```{r}
## R code 7.1
sppnames <- c( "afarensis","africanus","habilis","boisei",
               "rudolfensis","ergaster","sapiens")
brainvolcc <- c( 438 , 452 , 612, 521, 752, 871, 1350 )
masskg <- c( 37.0 , 35.5 , 34.5 , 41.5 , 55.5 , 61.0 , 53.5 )
d <- data.frame( species=sppnames , brain=brainvolcc , mass=masskg )
```


```{r}
## R code 7.2
d$mass_std <- (d$mass - mean(d$mass))/sd(d$mass)
d$brain_std <- d$brain / max(d$brain)
```


```{r}
## R code 7.3
m7.1 <- quap(
  alist(
    brain_std ~ dnorm( mu , exp(log_sigma) ),
    mu <- a + b*mass_std,
    a ~ dnorm( 0.5 , 1 ),
    b ~ dnorm( 0 , 10 ),
    log_sigma ~ dnorm( 0 , 1 )
  ), data=d )

## R code 7.4
set.seed(12)
s <- sim( m7.1 )
r <- apply(s,2,mean) - d$brain_std
resid_var <- var2(r)
outcome_var <- var2( d$brain_std )
1 - resid_var/outcome_var
```


```{r}
## R code 7.5
R2_is_bad <- function( quap_fit ) {
  s <- sim( quap_fit , refresh=0 )
  r <- apply(s,2,mean) - d$brain_std
  1 - var2(r)/var2(d$brain_std)
}

## R code 7.6
m7.2 <- quap(
  alist(
    brain_std ~ dnorm( mu , exp(log_sigma) ),
    mu <- a + b[1]*mass_std + b[2]*mass_std^2,
    a ~ dnorm( 0.5 , 1 ),
    b ~ dnorm( 0 , 10 ),
    log_sigma ~ dnorm( 0 , 1 )
  ), data=d , start=list(b=rep(0,2)) )

## R code 7.7
m7.3 <- quap(
  alist(
    brain_std ~ dnorm( mu , exp(log_sigma) ),
    mu <- a + b[1]*mass_std + b[2]*mass_std^2 +
      b[3]*mass_std^3,
    a ~ dnorm( 0.5 , 1 ),
    b ~ dnorm( 0 , 10 ),
    log_sigma ~ dnorm( 0 , 1 )
  ), data=d , start=list(b=rep(0,3)) )

m7.4 <- quap(
  alist(
    brain_std ~ dnorm( mu , exp(log_sigma) ),
    mu <- a + b[1]*mass_std + b[2]*mass_std^2 +
      b[3]*mass_std^3 + b[4]*mass_std^4,
    a ~ dnorm( 0.5 , 1 ),
    b ~ dnorm( 0 , 10 ),
    log_sigma ~ dnorm( 0 , 1 )
  ), data=d , start=list(b=rep(0,4)) )

m7.5 <- quap(
  alist(
    brain_std ~ dnorm( mu , exp(log_sigma) ),
    mu <- a + b[1]*mass_std + b[2]*mass_std^2 +
      b[3]*mass_std^3 + b[4]*mass_std^4 +
      b[5]*mass_std^5,
    a ~ dnorm( 0.5 , 1 ),
    b ~ dnorm( 0 , 10 ),
    log_sigma ~ dnorm( 0 , 1 )
  ), data=d , start=list(b=rep(0,5)) )

## R code 7.8
m7.6 <- quap(
  alist(
    brain_std ~ dnorm( mu , 0.001 ),
    mu <- a + b[1]*mass_std + b[2]*mass_std^2 +
      b[3]*mass_std^3 + b[4]*mass_std^4 +
      b[5]*mass_std^5 + b[6]*mass_std^6,
    a ~ dnorm( 0.5 , 1 ),
    b ~ dnorm( 0 , 10 )
  ), data=d , start=list(b=rep(0,6)) )
```


```{r}
## R code 7.9
post <- extract.samples(m7.1)
mass_seq <- seq( from=min(d$mass_std) , to=max(d$mass_std) , length.out=100 )
l <- link( m7.1 , data=list( mass_std=mass_seq ) )
mu <- apply( l , 2 , mean )
ci <- apply( l , 2 , PI )
plot( brain_std ~ mass_std , data=d )
lines( mass_seq , mu )
shade( ci , mass_seq )
```


```{r}
## R code 7.10
m7.1_OLS <- lm( brain_std ~ mass_std , data=d )
post <- extract.samples( m7.1_OLS )
```


```{r}
## R code 7.11
m7.7 <- quap(
  alist(
    brain_std ~ dnorm( mu , exp(log_sigma) ),
    mu <- a,
    a ~ dnorm( 0.5 , 1 ),
    log_sigma ~ dnorm( 0 , 1 )
  ), data=d )

## R code 7.12
#d_minus_i <- d[ -i , ]

## R code 7.13
p <- c( 0.3 , 0.7 )
-sum( p*log(p) )

## R code 7.14
set.seed(1)
lppd( m7.1 , n=1e4 )

## R code 7.15
set.seed(1)
logprob <- sim( m7.1 , ll=TRUE , n=1e4 )
head(logprob)
head(logprob) %>% exp()
dim(logprob)
n <- ncol(logprob)
ns <- nrow(logprob)
f <- function( i ) log_sum_exp( logprob[,i] ) - log(ns)
( lppd <- sapply( 1:n , f ) )
```


```{r}
## R code 7.16
set.seed(1)
sapply( list(m7.1,m7.2,m7.3,m7.4,m7.5,m7.6) , function(m) sum(lppd(m)) )
```


```{r, eval=FALSE}
## R code 7.17
N <- 20
kseq <- 1:5
dev <- sapply( kseq , function(k) {
  print(k);
  r <- replicate( 1e4 , sim_train_test( N=N, k=k ) );
  c( mean(r[1,]) , mean(r[2,]) , sd(r[1,]) , sd(r[2,]) )
} )
```


```{r, eval=FALSE}
## R code 7.18
r <- mcreplicate( 1e4 , sim_train_test( N=N, k=k ) , mc.cores=4 )
```


```{r, eval=FALSE}
## R code 7.19
plot( 1:5 , dev[1,] , ylim=c( min(dev[1:2,])-5 , max(dev[1:2,])+10 ) ,
      xlim=c(1,5.1) , xlab="number of parameters" , ylab="deviance" ,
      pch=16 , col=rangi2 )
mtext( concat( "N = ",N ) )
points( (1:5)+0.1 , dev[2,] )
for ( i in kseq ) {
  pts_in <- dev[1,i] + c(-1,+1)*dev[3,i]
  pts_out <- dev[2,i] + c(-1,+1)*dev[4,i]
  lines( c(i,i) , pts_in , col=rangi2 )
  lines( c(i,i)+0.1 , pts_out )
}

```


Generate a model with which to compute WAIC.  Fit it and extract posterior

```{r}
## R code 7.20
data(cars)
m <- quap(
  alist(
    dist ~ dnorm(mu,sigma),
    mu <- a + b*speed,
    a ~ dnorm(0,100),
    b ~ dnorm(0,10),
    sigma ~ dexp(1)
  ) , data=cars )
set.seed(94)
post <- extract.samples(m,n=1000)
head(post)
```

now we compute the log probability of each observation, across the posterior
```{r}
## R code 7.21
n_samples <- 1000
logprob <- sapply( 1:n_samples ,
                   function(s) {
                     mu <- post$a[s] + post$b[s]*cars$speed
                     dnorm( cars$dist , mu , post$sigma[s] , log=TRUE )
                   } )
dim(cars)
dim(logprob)
logprob[1:10,1:10]
```

This is 50 X 1000.  50 because there are 50 observations in the data set, and 1000 becuase there are 1000 posterior samples.  So each cell is the log probability of that observation for that draw of the posterior


Now, for each sample, we want the average log probability. To this we want to sum the probabilities across the posterior samples and then average.  For this, we exponentiate, sum, and then take the log again.  Finally we subtract by the log of the number of samples, which is the same as dividing by the number of samples.

```{r}
## R code 7.22
n_cases <- nrow(cars)
lppd <- sapply( 1:n_cases , function(i) log_sum_exp(logprob[i,]) - log(n_samples) )
lppd
sum(lppd)
```

now this is the average log probablility of each observation

```{r}
## R code 7.23
pWAIC <- sapply( 1:n_cases , function(i) var(logprob[i,]) )
pWAIC
sum(pWAIC)
```
For each sample, the variance in its probability across the posterior samples.

WAIC:
```{r}
## R code 7.24
-2*( sum(lppd) - sum(pWAIC) )
```

Compare to WAIC
```{r}
WAIC(m)
```


```{r}
## R code 7.25
waic_vec <- -2*( lppd - pWAIC )
sqrt( n_cases*var(waic_vec) )
```

```{r}
## R code 7.33
data(Primates301)
d <- Primates301
```


```{r}
## R code 7.34
d$log_L <- scale( log(d$longevity) )
d$log_B <- scale( log(d$brain) )
d$log_M <- scale( log(d$body) )
```


```{r}
## R code 7.35
sapply( d[,c("log_L","log_B","log_M")] , function(x) sum(is.na(x)) )
```


```{r}
## R code 7.36
d2 <- d[ complete.cases( d$log_L , d$log_M , d$log_B ) , ]
nrow(d2)
```


```{r}
## R code 7.37
m7.8 <- quap(
    alist(
        log_L ~ dnorm( mu , sigma ),
        mu <- a + bM*log_M + bB*log_B,
        a ~ dnorm(0,0.1),
        bM ~ dnorm(0,0.5),
        bB ~ dnorm(0,0.5),
        sigma ~ dexp(1)
    ) , data=d2 )
```

```{r}
prior <- extract.prior(m7.8)
mu.prior <- link(m7.8, post=prior)
dens(exp(mu.prior),xlim=c(-2,10))
dens(exp(d2$log_L))
```


```{r}
## R code 7.38
m7.9 <- quap(
    alist(
        log_L ~ dnorm( mu , sigma ),
        mu <- a + bB*log_B,
        a ~ dnorm(0,0.1),
        bB ~ dnorm(0,0.5),
        sigma ~ dexp(1)
    ) , data=d2 )
m7.10 <- quap(
    alist(
        log_L ~ dnorm( mu , sigma ),
        mu <- a + bM*log_M,
        a ~ dnorm(0,0.1),
        bM ~ dnorm(0,0.5),
        sigma ~ dexp(1)
    ) , data=d2 )
```


```{r}
## R code 7.39
set.seed(301)
compare( m7.8 , m7.9 , m7.10 )
```


```{r}
## R code 7.40
plot( compare( m7.8 , m7.9 , m7.10 ) )
```


```{r}
## R code 7.41
plot( coeftab( m7.8 , m7.9 , m7.10 ) , pars=c("bM","bB") )
```


```{r}
## R code 7.42
cor( d2$log_B , d2$log_M )

## R code 7.43
waic_m7.8 <- WAIC( m7.8 , pointwise=TRUE )
waic_m7.9 <- WAIC( m7.9 , pointwise=TRUE )
```


```{r}
## R code 7.44
# compute point scaling
x <- d2$log_B - d2$log_M
x <- x - min(x)
x <- x / max(x)

# draw the plot
plot( waic_m7.8 - waic_m7.9 , d2$log_L ,
    xlab="pointwise difference in WAIC" , ylab="log longevity (std)" , pch=21 ,
    col=col.alpha("black",0.8) , cex=1+x , lwd=2 , bg=col.alpha(rangi2,0.4) )
abline( v=0 , lty=2 )
abline( h=0 , lty=2 )
```


```{r}
## R code 7.45
m7.11 <- quap(
    alist(
        log_B ~ dnorm( mu , sigma ),
        mu <- a + bM*log_M + bL*log_L,
        a ~ dnorm(0,0.1),
        bM ~ dnorm(0,0.5),
        bL ~ dnorm(0,0.5),
        sigma ~ dexp(1)
    ) , data=d2 )
precis( m7.11 )
```


```{r}
## R code 7.46
library(rethinking)
data(Howell1)
d <- Howell1
d$age <- (d$age - mean(d$age))/sd(d$age)
set.seed( 1000 )
i <- sample(1:nrow(d),size=nrow(d)/2)
d1 <- d[ i , ]
d2 <- d[ -i , ]
```


```{r, eval=FALSE}
## R code 7.47
sum( dnorm( d2$height , mu , sigma , log=TRUE ) )
```

