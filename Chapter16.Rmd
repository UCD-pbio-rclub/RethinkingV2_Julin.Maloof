---
title: "Chapter 16"
author: "Julin Maloof"
date: "8/3/2020"
output: html_notebook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, autodep = TRUE)
```

## Problems
```{r}
library(rethinking)
library(tidyverse)
```

### 16M1
_Modify the cylinder height model, m16.1, so that the exponent 3 on height is instead a free parameter. Do you recover the value of 3 or not? Plot the posterior predictions for the new model. How do they differ from those of m16.1?_

Data and original model
```{r}
data(Howell1)
d <- Howell1

# scale observed variables
d$w <- d$weight / mean(d$weight)
d$h <- d$height / mean(d$height)

## R code 16.2
m16.1 <- ulam(
    alist(
        w ~ dlnorm( mu , sigma ),
        exp(mu) <- 3.141593 * k * p^2 * h^3,
        p ~ beta( 2 , 18 ),
        k ~ exponential( 0.5 ),
        sigma ~ exponential( 1 )
    ), data=d , chains=4 , cores=4 )
```

plot some exp distributions
```{r}
x <- seq(0,10,.1)
plotd <- tibble(rate=seq(0.1,1.1,.2)) %>%
    mutate(dist=map(rate, ~ data.frame(x=x,y=dexp(x, rate=.)))) %>% 
    unnest()

plotd
plotd %>% ggplot(aes(x=x,y=y, group=rate, color=as.factor(rate))) +
    geom_line()
```
Plot some gamma distributions:
```{r}
x <- seq(0,10,.1)
plotd <- tibble(shape=seq(1,10,2)) %>%
    mutate(dist=map(shape, ~ data.frame(x=x,
                                        y=dgamma(x, shape=., rate=1)))) %>% 
    unnest()

plotd
plotd %>% ggplot(aes(x=x,y=y, group=shape, color=as.factor(shape))) +
    geom_line()
```

```{r}
x <- seq(0,10,.1)
plotd <- tibble(shape=seq(1,10,2)) %>%
    mutate(dist=map(shape, ~ data.frame(x=x,
                                        y=dgamma(x, shape=., rate=2)))) %>% 
    unnest()

plotd
plotd %>% ggplot(aes(x=x,y=y, group=shape, color=as.factor(shape))) +
    geom_line()
```


rethinking does weird change to gamma dist:
```{r}
## R code 16.2
m16m1 <- ulam(
    alist(
        w ~ dlnorm( mu , sigma ),
        exp(mu) <- 3.141593 * k * p^2 * h^a,
        a ~ gamma(7, .5),
        p ~ beta( 2 , 18 ),
        k ~ exponential( 0.5 ),
        sigma ~ exponential( 1 )
    ), data=d , chains=4 , cores=4 )
stancode(m16m1)
```

```{r}
## R code 16.2
m16m1.alt <- ulam(
    alist(
        w ~ dlnorm( mu , sigma ),
        exp(mu) <- 3.141593 * k * p^2 * h^a,
        a ~ exponential(0.3),
        p ~ beta( 2 , 18 ),
        k ~ exponential( 0.5 ),
        sigma ~ exponential( 1 )
    ), data=d , chains=4 , cores=4 )
```

```{r}
precis(m16.1)
```

```{r}
precis(m16m1)
```


```{r}
precis(m16m1.alt)
```


Plot 
```{r}
## R code 16.3
h_seq <- seq( from=0 , to=max(d$h) , length.out=30 )
w_sim <- sim( m16.1 , data=list(h=h_seq) )
mu_mean <- apply( w_sim , 2 , mean )
w_CI <- apply( w_sim , 2 , PI )
plot( d$h , d$w , xlim=c(0,max(d$h)) , ylim=c(0,max(d$w)) , col=rangi2 ,
      lwd=2 , xlab="height (scaled)" , ylab="weight (scaled)" )
lines( h_seq , mu_mean )
shade( w_CI , h_seq )

## plus estimate from new model
w_sim2 <- sim( m16m1.alt , data=list(h=h_seq) )
mu_mean2 <- apply( w_sim2 , 2 , mean )
w_CI2 <- apply( w_sim2 , 2 , PI )
lines( h_seq , mu_mean2, lty=2 )
shade( w_CI2 , h_seq, col=col.alpha("yellow",
                                    0.25) )
```
This does a better job on the tails, maybe less good in the middle?  Real problem is that it looks to me like there is a mixed distribution here.

### 16M2
_Conduct a prior predictive simulation for the cylinder height model. Begin with the priors in the chapter. Do these produce reasonable prior height distributions? If not, which modifications do you suggest?_

Data and original model
```{r, eval=FALSE}
data(Howell1)
d <- Howell1

# scale observed variables
d$w <- d$weight / mean(d$weight)
d$h <- d$height / mean(d$height)

## R code 16.2
m16.1 <- ulam(
    alist(
        w ~ dlnorm( mu , sigma ),
        exp(mu) <- 3.141593 * k * p^2 * h^3,
        p ~ beta( 2 , 18 ),
        k ~ exponential( 0.5 ),
        sigma ~ exponential( 1 )
    ), data=d , chains=4 , cores=4 )
```

Trying to understand the scaling
```{r}
post <- as.data.frame(extract.samples(m16.1))
str(post)
post <- post %>% mutate(mu=log(pi*k*p^2*1^3))
head(post)
```
nope

```{r}
post <- as.data.frame(extract.samples(m16.1))
str(post)
post <- post %>% mutate(mu=pi*k*p^2*1^3)
head(post)
```
yep

so why not remove exp and make it normally distributed?
```{r}

m16.1.norm <- ulam(
    alist(
        w ~ dnorm( mu , sigma ),
        mu <- 3.141593 * k * p^2 * h^3,
        p ~ beta( 2 , 18 ),
        k ~ exponential( 0.5 ),
        sigma ~ exponential( 1 )
    ), data=d , chains=4 , cores=4 )

precis(m16.1.norm)
```
Does not sample as well but more or less works.

back to the prior:

100 draws from the prior
```{r}
prior1 <- tibble(
    i=1:100,
    p=rbeta(100, 2, 18),
    k=rexp(100, .5)
)
prior1
```
draw a curve for each of these 100:
```{r}
prior1 %>% group_by(i) %>%
    mutate(results=map2(p,k, function(p,k) {
        tibble(h=h_seq,
               w=pi * k * p^2 * h_seq^3)})) %>%
    unnest() %>%
    ggplot(aes(x=h,y=w)) +
    geom_line(aes(group=i), alpha=.2) +
    geom_point(data = d, shape=1, alpha=.5, color="blue")
```
Not so good!

Try again:
```{r}
tibble(
    i=1:100,
    p=rbeta(100, 5, 10),
    k=rexp(100, .5)
) %>% group_by(i) %>%
    mutate(results=map2(p,k, function(p,k) {
        tibble(h=h_seq,
               w=pi * k * p^2 * h_seq^3)})) %>%
    unnest() %>%
    ggplot(aes(x=h,y=w)) +
    geom_line(aes(group=i), alpha=.2) +
    geom_point(data = d, shape=1, alpha=.5, color="blue")
```

Plot old and new prior for p
```{r}
x <- seq(0,1,.01)
d <- tibble(shape1=c(2,5),shape2=c(18,10),prior=c("old", "new")) %>%
    mutate(dist=map2(shape1, shape2,
                     ~ data.frame(
                         x=x,
                         y=dbeta(x, shape1=.x, shape2 = .y)))) %>% 
    unnest()

d %>% ggplot(aes(x=x,y=y, group=prior, color=as.factor(prior))) +
    geom_line()
```


## Book

```{r, eval=FALSE}
## R code 16.1
library(rethinking)
data(Howell1)
d <- Howell1

# scale observed variables
d$w <- d$weight / mean(d$weight)
d$h <- d$height / mean(d$height)

## R code 16.2
m16.1 <- ulam(
    alist(
        w ~ dlnorm( mu , sigma ),
        exp(mu) <- 3.141593 * k * p^2 * h^3,
        p ~ beta( 2 , 18 ),
        k ~ exponential( 0.5 ),
        sigma ~ exponential( 1 )
    ), data=d , chains=4 , cores=4 )
```

```{r, eval=FALSE}
precis(m16.1)
```

```{r, eval=FALSE}
pairs(m16.1)
```


```{r, eval=FALSE}
## R code 16.3
h_seq <- seq( from=0 , to=max(d$h) , length.out=30 )
w_sim <- sim( m16.1 , data=list(h=h_seq) )
mu_mean <- apply( w_sim , 2 , mean )
w_CI <- apply( w_sim , 2 , PI )
plot( d$h , d$w , xlim=c(0,max(d$h)) , ylim=c(0,max(d$w)) , col=rangi2 ,
      lwd=2 , xlab="height (scaled)" , ylab="weight (scaled)" )
lines( h_seq , mu_mean )
shade( w_CI , h_seq )
```

```{r, eval=FALSE}
x <- seq(0,10,.01)
plot(x,dlnorm(x))
plot(x,log(dlnorm(x)))
plot(log(x),log(dlnorm(x)))

```

```{r, eval=FALSE}
## R code 16.4
library(rethinking)
data(Boxes)
precis(Boxes)

## R code 16.5
table( Boxes$y ) / length( Boxes$y )
```


```{r, eval=FALSE}
## R code 16.6
set.seed(7)
N <- 30 # number of children

# half are random
# sample from 1,2,3 at random for each
y1 <- sample( 1:3 , size=N/2 , replace=TRUE )

# half follow majority
y2 <- rep( 2 , N/2 )

# combine and shuffle y1 and y2
y <- sample( c(y1,y2) )

# count the 2s
sum(y==2)/N
```


```{r, eval=FALSE}
## R code 16.7
data(Boxes_model)
cat(Boxes_model)
```


```{r, eval=FALSE}
## R code 16.8
# prep data
dat_list <- list(
    N = nrow(Boxes),
    y = Boxes$y,
    majority_first = Boxes$majority_first )

# run the sampler
m16.2 <- stan( model_code=Boxes_model , data=dat_list , chains=3 , cores=3 )

# show marginal posterior for p
p_labels <- c("1 Majority","2 Minority","3 Maverick","4 Random","5 Follow First")
plot( precis(m16.2,2) , labels=p_labels )
```


```{r, eval=FALSE}
## R code 16.8 rnndomized
# prep data
dat_list <- list(
    N = nrow(Boxes),
    y = sample(1:3, size=nrow(Boxes), replace = TRUE),
    majority_first = Boxes$majority_first )

# run the sampler
m16.2 <- stan( model_code=Boxes_model , data=dat_list , chains=3 , cores=3 )

# show marginal posterior for p
p_labels <- c("1 Majority","2 Minority","3 Maverick","4 Random","5 Follow First")
plot( precis(m16.2,2) , labels=p_labels )
```


```{r, eval=FALSE}
## R code 16.9
library(rethinking)
data(Panda_nuts)
```


```{r, eval=FALSE}
## R code 16.10
N <- 1e4
phi <- rlnorm( N , log(1) , 0.1 )
k <- rlnorm( N , log(2), 0.25 )
theta <- rlnorm( N , log(5) , 0.25 )

# relative grow curve
plot( NULL , xlim=c(0,1.5) , ylim=c(0,1) , xaxt="n" , xlab="age" ,
      ylab="body mass" )
at <- c(0,0.25,0.5,0.75,1,1.25,1.5)
axis( 1 , at=at , labels=round(at*max(Panda_nuts$age)) )
for ( i in 1:20 ) curve( (1-exp(-k[i]*x)) , add=TRUE , col=grau() , lwd=1.5 )

# implied rate of nut opening curve
plot( NULL , xlim=c(0,1.5) , ylim=c(0,1.2) , xaxt="n" , xlab="age" ,
      ylab="nuts per second" )
at <- c(0,0.25,0.5,0.75,1,1.25,1.5)
axis( 1 , at=at , labels=round(at*max(Panda_nuts$age)) )
for ( i in 1:20 ) curve( phi[i]*(1-exp(-k[i]*x))^theta[i] , add=TRUE ,
                         col=grau() , lwd=1.5 )
```
```{r, eval=FALSE}
dens(phi)
dens(k)
dens(theta)
```


```{r, eval=FALSE}
## R code 16.11
dat_list <- list(
    n = as.integer( Panda_nuts$nuts_opened ),
    age = Panda_nuts$age / max(Panda_nuts$age),
    seconds = Panda_nuts$seconds )

m16.4 <- ulam(
    alist(
        n ~ poisson( lambda ),
        lambda <- seconds*phi*(1-exp(-k*age))^theta,
        phi ~ lognormal( log(1) , 0.1 ),
        k ~ lognormal( log(2) , 0.25 ),
        theta ~ lognormal( log(5) , 0.25 )
    ), data=dat_list , chains=4 )
```
```{r}
precis(m16.4)
```

```{r, eval=FALSE}
## R code 16.11 JM
dat_list <- list(
    n = as.integer( Panda_nuts$nuts_opened ),
    age = Panda_nuts$age ,
    seconds = Panda_nuts$seconds )

m16.4JM <- ulam(
    alist(
        n ~ poisson( lambda ),
        lambda <- seconds*phi*(1-exp(-k*age))^theta,
        phi ~ lognormal( log(1) , 0.1 ),
        k ~ lognormal( log(2) , 0.25 ),
        theta ~ lognormal( log(5) , 0.25 )
    ), data=dat_list , chains=4 )
```

```{r}
precis(m16.4JM)
```

```{r, eval=FALSE}
## R code 16.12
post <- extract.samples(m16.4)
plot( NULL , xlim=c(0,1) , ylim=c(0,1.5) , xlab="age" ,
      ylab="nuts per second" , xaxt="n" )
at <- c(0,0.25,0.5,0.75,1,1.25,1.5)
axis( 1 , at=at , labels=round(at*max(Panda_nuts$age)) )

# raw data
pts <- dat_list$n / dat_list$seconds
point_size <- normalize( dat_list$seconds )
points( jitter(dat_list$age) , pts , col=rangi2 , lwd=2 , cex=point_size*3 )

# 30 posterior curves
for ( i in 1:30 ) with( post ,
                        curve( phi[i]*(1-exp(-k[i]*x))^theta[i] , add=TRUE , col=grau() ) )
```


```{r, eval=FALSE}
## R code 16.13
library(rethinking)
data(Lynx_Hare)
plot( 1:21 , Lynx_Hare[,3] , ylim=c(0,90) , xlab="year" ,
      ylab="thousands of pelts" , xaxt="n" , type="l" , lwd=1.5 )
at <- c(1,11,21)
axis( 1 , at=at , labels=Lynx_Hare$Year[at] )
lines( 1:21 , Lynx_Hare[,2] , lwd=1.5 , col=rangi2 )
points( 1:21 , Lynx_Hare[,3] , bg="black" , col="white" , pch=21 , cex=1.4 )
points( 1:21 , Lynx_Hare[,2] , bg=rangi2 , col="white" , pch=21 , cex=1.4 )
text( 17 , 80 , "Lepus" , pos=2 )
text( 19 , 50 , "Lynx" , pos=2 , col=rangi2 )

## R code 16.14
sim_lynx_hare <- function( n_steps , init , theta , dt=0.002 ) {
    L <- rep(NA,n_steps)
    H <- rep(NA,n_steps)
    L[1] <- init[1]
    H[1] <- init[2]
    for ( i in 2:n_steps ) {
        H[i] <- H[i-1] + dt*H[i-1]*( theta[1] - theta[2]*L[i-1] )
        L[i] <- L[i-1] + dt*L[i-1]*( theta[3]*H[i-1] - theta[4] )
    }
    return( cbind(L,H) )
}

## R code 16.15
theta <- c( 0.5 , 0.05 , 0.025 , 0.5 )
z <- sim_lynx_hare( 1e4 , as.numeric(Lynx_Hare[1,2:3]) , theta )

plot( z[,2] , type="l" , ylim=c(0,max(z[,2])) , lwd=2 , xaxt="n" ,
      ylab="number (thousands)" , xlab="" )
lines( z[,1] , col=rangi2 , lwd=2 )
mtext( "time" , 1 )

## R code 16.16
N <- 1e4
Ht <- 1e4
p <- rbeta(N,2,18)
h <- rbinom( N , size=Ht , prob=p )
h <- round( h/1000 , 2 )
dens( h , xlab="thousand of pelts" , lwd=2 )

## R code 16.17
data(Lynx_Hare_model)
cat(Lynx_Hare_model)

## R code 16.18
dat_list <- list(
    N = nrow(Lynx_Hare),
    pelts = Lynx_Hare[,2:3] )

m16.5 <- stan( model_code=Lynx_Hare_model , data=dat_list , chains=3 , cores=3 ,
               control=list( adapt_delta=0.95 ) )

## R code 16.19
post <- extract.samples(m16.5)
pelts <- dat_list$pelts
plot( 1:21 , pelts[,2] , pch=16 , ylim=c(0,120) , xlab="year" ,
      ylab="thousands of pelts" , xaxt="n" )
at <- c(1,11,21)
axis( 1 , at=at , labels=Lynx_Hare$Year[at] )
points( 1:21 , pelts[,1] , col=rangi2 , pch=16 )
# 21 time series from posterior
for ( s in 1:21 ) {
    lines( 1:21 , post$pelts_pred[s,,2] , col=col.alpha("black",0.2) , lwd=2 )
    lines( 1:21 , post$pelts_pred[s,,1] , col=col.alpha(rangi2,0.3) , lwd=2 )
}
# text labels
text( 17 , 90 , "Lepus" , pos=2 )
text( 19 , 50 , "Lynx" , pos=2 , col=rangi2 )

## R code 16.20
plot( NULL , pch=16 , xlim=c(1,21) , ylim=c(0,500) , xlab="year" ,
      ylab="thousands of animals" , xaxt="n" )
at <- c(1,11,21)
axis( 1 , at=at , labels=Lynx_Hare$Year[at] )
for ( s in 1:21 ) {
    lines( 1:21 , post$pop[s,,2] , col=col.alpha("black",0.2) , lwd=2 )
    lines( 1:21 , post$pop[s,,1] , col=col.alpha(rangi2,0.4) , lwd=2 )
}

## R code 16.21
data(Lynx_Hare)
dat_ar1 <- list(
    L = Lynx_Hare$Lynx[2:21],
    L_lag1 = Lynx_Hare$Lynx[1:20],
    H = Lynx_Hare$Hare[2:21],
    H_lag1 = Lynx_Hare$Hare[1:20] )
```

