---
title: "Chapter 13"
author: "Julin N Maloof"
date: "1/8/2020"
output: 
  html_document: 
    keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, autodep = TRUE)
```

# Problems


## 12E1

_12E1. Which of the following priors will produce more shrinkage in the estimates? (a) αtank ∼
Normal(0, 1); (b) αtank ∼ Normal(0, 2)._

αtank ∼ Normal(0, 1)

## 12E2

_Make the following model into a multilevel model._

Old:
yi ∼ Binomial(1, pi)  
logit(pi) = αgroup[i] + βxi   
αgroup ∼ Normal(0, 1.5)  
β ∼ Normal(0, 1)

New:
yi ∼ Binomial(1, pi)  
logit(pi) = αgroup[i] + βxi   
αgroup ∼ Normal(a_bar, sigma)  
a_bar ~ Normal(0, 1.5)  
sigma ~ dexp(0,1)  
β ∼ Normal(0, 1)


## 12E3

_Make the following model into a multilevel model._

yi ∼ Normal(μi, σ)  
μi = αgroup[i] + βxi  
αgroup ∼ Normal(a_bar, sigma)  
a_bar ~ Normal(0, 10)  
sigma ~ dexp(1)  
β ∼ Normal(0, 1)  
σ ∼ HalfCauchy(0, 2)

## 12M1

_Revisit the Reed frog survival data, data(reedfrogs), and add the predation and size treatment variables to the varying intercepts model. Consider models with either main effect alone, both main effects, as well as a model including both and their interaction. Instead of focusing on inferences about these two predictor variables, focus on the inferred variation across tanks. Explain why it changes as it does across models._

```{r}
library(rethinking)
library(tidyverse)
data(reedfrogs)
d <- reedfrogs
str(d)

# make the tank cluster variable
d$tank <- 1:nrow(d)


```

orignal
```{r, warning=FALSE}
dat <- list(
  S = d$surv,
  N = d$density,
  tank = d$tank
)

m12M1a <- ulam(
  alist(
    S ~ dbinom( N , p ) ,
    logit(p) <- a[tank] ,
    a[tank] ~ dnorm( a_bar , sigma ) ,
    a_bar ~ dnorm( 0 , 1.5 ) ,
    sigma ~ dexp( 1 )
  ), data=dat , chains=4 , log_lik=TRUE )
```

```{r, warning=FALSE}
dat <- list(
  S = d$surv,
  N = d$density,
  tank = d$tank,
  pred = ifelse(d$pred=="no", 0, 1)
)

m12M1_pred <- ulam(
  alist(
    S ~ dbinom( N , p ) ,
    logit(p) <- a[tank] + b_pred*pred,
    a[tank] ~ dnorm( a_bar , sigma ) ,
    a_bar ~ dnorm( 0 , 1.5 ) ,
    b_pred ~ dnorm(0, 1),
    sigma ~ dexp( 1 )
  ), data=dat , chains=4 , log_lik=TRUE, iter = 2000 )
```

```{r}
precis(m12M1_pred, depth = 2)
plot(m12M1_pred)
```


size model
```{r,  warning=FALSE}
dat <- list(
  S = d$surv,
  N = d$density,
  tank = d$tank,
  sze = ifelse(d$size=="small", 0, 1)
)

str(dat)

m12M1_size <- ulam(
  alist(
    S ~ dbinom( N , p ) ,
    logit(p) <- a[tank] + b_size*sze,
    a[tank] ~ dnorm( a_bar , sigma ) ,
    a_bar ~ dnorm( 0 , 1.5 ) ,
    b_size ~ dnorm(0, 1),
    sigma ~ dexp( 1 )
  ), data=dat , chains=4 , iter=4000, log_lik=TRUE )
```

```{r}
precis(m12M1_size)
```


both size and pred
```{r, warning=FALSE}
dat <- list(
  S = d$surv,
  N = d$density,
  tank = d$tank,
  sze = ifelse(d$size=="small", 0, 1),
  pred = ifelse(d$pred=="no", 0, 1)
)

m12M1_both <- ulam(
  alist(
    S ~ dbinom( N , p ) ,
    logit(p) <- a[tank] + b_pred*pred + b_size*sze,
    a[tank] ~ dnorm( a_bar , sigma ) ,
    a_bar ~ dnorm( 0 , 1.5 ) ,
    b_pred ~ dnorm(0, 1),
    b_size ~ dnorm(0, 1),
    sigma ~ dexp( 1 )
  ), data=dat , chains=4 , log_lik=TRUE, iter=4000 )
```

```{r}
precis(m12M1_both)
```


interaction
```{r, warning=FALSE}
dat <- list(
  S = d$surv,
  N = d$density,
  tank = d$tank,
  sze = ifelse(d$size=="small", 0, 1),
  pred = ifelse(d$pred=="no", 0, 1)
)

m12M1_int <- ulam(
  alist(
    S ~ dbinom( N , p ) ,
    logit(p) <- a[tank] + b_pred*pred + b_size*sze +b_int*pred*sze,
    a[tank] ~ dnorm( a_bar , sigma ) ,
    a_bar ~ dnorm( 0 , 1.5 ) ,
    b_pred ~ dnorm(0, 1),
    b_size ~ dnorm(0, 1),
    b_int ~ dnorm(0, .5),
    sigma ~ dexp( 1 )
  ), data=dat , chains=4 , log_lik=TRUE, iter=4000 )
```

```{r}
precis(m12M1_int)
```

```{r}
coeftab(m12M1a, m12M1_pred, m12M1_size, m12M1_both, m12M1_int)@coefs %>% 
  as.data.frame() %>%
  rownames_to_column(var="coef") %>%
  filter(str_detect(coef, "\\[", negate = TRUE))
```

sigma represents the estimated variation (or really the standard deviation) between tanks.  It turns out that some of that variation is caused by differences in predation and size, so when those variables are included in the model, the "residual" tank to tank variation is reduced.


## 12M2

_Compare the models you fit just above, using WAIC. Can you reconcile the differences in WAIC with the posterior distributions of the models?_

```{r}
compare(m12M1a, m12M1_pred, m12M1_size, m12M1_both, m12M1_int)
```

I would have thought that the pred or both models would have been notably better than the intercept only model.

## 12M3

Re-estimate the basic Reed frog varying intercept model, but now using a Cauchy distribution in place of the Gaussian distribution for the varying intercepts.

Compare the posterior means of the intercepts, αtank, to the posterior means produced in the chapter, using the customary Gaussian prior. Can you explain the pattern of differences?

```{r, warning=FALSE, results='hide'}
dat <- list(
  S = d$surv,
  N = d$density,
  tank = d$tank
)

m12M3 <- ulam(
  alist(
    S ~ dbinom( N , p ) ,
    logit(p) <- a[tank] ,
    a[tank] ~ dcauchy( a_bar , sigma ) ,
    a_bar ~ dnorm( 0 , 1.5 ) ,
    sigma ~ dcauchy(0, 1)
  ), data=dat , chains=4 , log_lik=TRUE )
```

now compare the models.
```{r}
precis(m12M1a)
precis(m12M3)
compare(m12M1a, m12M3)
```

```{r}
pred.orig <- link(m12M1a)

pred.cauchy <- link(m12M3)

results <-rbind(
  data.frame(
    tank=1:48,
    mu=apply(pred.orig, 2, mean),
    hdpi.low=apply(pred.orig, 2, HPDI)[1,],
    hdpi.high=apply(pred.orig, 2, HPDI)[2,],
    model="Gaussian"),
  data.frame(
    tank=1:48,
    mu=apply(pred.cauchy, 2, mean),
    hdpi.low=apply(pred.cauchy, 2, HPDI)[1,],
    hdpi.high=apply(pred.cauchy, 2, HPDI)[2,],
    model="Cauchy")
)
```

```{r}
results %>%
  ggplot(aes(x=tank, y=mu, ymin=hdpi.low, ymax=hdpi.high, color=model, shape=model)) +
  geom_point(size=2) +
  theme(axis.text.x = element_text(angle=90, hjust=1))
```

```{r}
results %>%
  ggplot(aes(x=model, y=mu, group=tank)) +
  geom_line()
```

Cuachy distribution has fatter tails so we see a bit of a spread in the tank estimates....


## 12H1

```{r}
data("bangladesh")
d <- bangladesh
d$district_id <- as.integer(as.factor(d$district))
str(d)
```

fixed effect model
```{r, warning=FALSE}
dat = list(district_id=d$district_id, contraception=d$use.contraception)
str(dat)
M12H1a <- ulam(
  alist(contraception ~ dbinom(1, p),
        logit(p) <- a[district_id],
        a[district_id] ~ dnorm(0, 1.5)),
  data = dat, chains = 4, log_lik = TRUE)
```

```{r}
precis(M12H1a, depth=2) %>% head()
```

multi-level model:
```{r, warning=FALSE}
M12H1b <- ulam(
  alist(contraception ~ dbinom(1, p),
        logit(p) <- a[district_id],
        a[district_id] ~ dnorm(a_bar, sigma),
        a_bar ~ dnorm(0, 1.5),
        sigma ~ dexp(1)),
  data = dat, chains = 4, log_lik = TRUE, cores=4 )
```

```{r}
precis(M12H1b, depth=2) %>% head()
```

```{r}
compare(M12H1a, M12H1b)
```
Hierarchical model strongly preferred

#### make the plots...

First, get posterior samples
```{r}
pred.df <- data.frame(district_id=unique(dat$district_id))
pred1 <- link(M12H1a, pred.df)
dim(pred1)
pred1[1:5, 1:5]
range(pred1) #already transformed
pred2 <- link(M12H1b, pred.df)
```

summarize samples
```{r}
results1 <- data.frame(
  district_id=1:60,
  mu=apply(pred1, 2, mean),
  hdpi.low=apply(pred1, 2, HPDI)[1,],
  hdpi.high=apply(pred1, 2, HPDI)[2,],
  model="fixed")

results2 <- data.frame(
  district_id=1:60,
  mu=apply(pred2, 2, mean),
  hdpi.low=apply(pred2, 2, HPDI)[1,],
  hdpi.high=apply(pred2, 2, HPDI)[2,],
  model="hierarchical")

resultsall <- rbind(results1, results2)
head(resultsall)
```

add sample size per district so that I can use this in plotting:
```{r}
resultsall <- d %>% 
  group_by(district_id) %>%
  summarize(size=n()) %>%
  right_join(resultsall)
```

I want to order the plotting by the differnce between the models

```{r}
resultsdiff <- 
  resultsall %>%
  select(district_id, size, model, mu) %>%
  spread(key = model, value = mu) %>% 
  mutate(diff=abs(fixed-hierarchical))

plotorder <- resultsdiff  %>%
  arrange(diff) %>%
  pull(district_id) %>% 
  as.character()
```



```{r, fig.width=10}
hlines <- data.frame(
  average=c("fixed", "hierarchical"),
  estimate=c(mean(d$use.contraception),
             inv_logit(coef(M12H1b)["a_bar"])
  ))

resultsall %>%
  ggplot(aes(x=as.factor(district_id), y=mu, ymin=hdpi.low, ymax=hdpi.high, fill=model, color=model, shape=model, size=size)) +
  geom_point() +
  scale_x_discrete(limits=plotorder) +
  geom_hline(aes(yintercept = estimate, linetype = average), data=hlines) +
  theme(axis.text.x = element_text(angle=90, hjust=1),panel.grid.major.x = element_blank()) +
  ylab("proportion using contraception") +
  xlab("district")

```

Two determinants: sample size and distance from overall mean

```{r}
resultsdiff %>% 
  ggplot(aes(x=size,y=diff)) +
  geom_point() +
  geom_smooth()
```

```{r}
resultsdiff %>% 
  mutate(distance.from.abar=abs(fixed-inv_logit(coef(M12H1b)["a_bar"]))) %>%
  ggplot(aes(x=distance.from.abar,y=diff)) +
  geom_point() +
  geom_smooth()
```

## 12H2

_Return to the Trolley data, data(Trolley), from Chapter 12. Define and fit a varying intercepts model for these data. Cluster intercepts on individual participants, as indicated by the unique values in the id variable. Include action, intention, and contact as ordinary terms. Compare the varying intercepts model and a model that ignores individuals, using both WAIC and posterior predictions. What is the impact of individual variation in these data?_

```{r}
data(Trolley)

dat <- list(
  R = d$response,
  A = d$action,
  I = d$intention,
  C = d$contact,
  id = d$id)

system.time({
  m12H2a <- ulam(
    alist(
      R ~ dordlogit( phi , cutpoints ),
      phi <- bA*A + bC*C + BI*I ,
      BI <- bI + bIA*A + bIC*C ,
      c(bA,bI,bC,bIA,bIC) ~ dnorm( 0 , 0.5 ),
      cutpoints ~ dnorm( 0 , 1.5 )
    ) , data=dat , chains=4 , cores=4 )
})
```


```{r}
system.time({
  m12H2b <- ulam( alist(
  R ~ dordlogit( phi , cutpoints ),
  phi <- alpha[id] + bA*A + bC*C + BI*I ,
  BI <- bI + bIA*A + bIC*C , 
  alpha[id] ~ dnorm(alpha_bar, sigma)
  alpha_bar ~ dnorm(0, 1.5)
  c(bA,bI,bC,bIA,bIC) ~ dnorm( 0 , 0.5 ), 
  cutpoints ~ dnorm( 0 , 1.5 ),
  sigma ~ dexp(1)) ,
  data=dat, 
  chains=4, 
  cores=4)
})
```

```{r}
precis(m12H2a)
precis(m12H2b)
compare(m12H2a, m12H2b)
```

```{r}
plot(coeftab(m12H2a, m12H2b))
```


# Book

```{r}
knitr::opts_chunk$set(eval = FALSE)
```


```{r}
## R code 13.1
library(rethinking)
data(reedfrogs)
d <- reedfrogs
str(d)

## R code 13.2
# make the tank cluster variable
d$tank <- 1:nrow(d)

dat <- list(
  S = d$surv,
  N = d$density,
  tank = d$tank )
```


```{r}
# approximate posterior
m13.1 <- ulam(
  alist(
    S ~ dbinom( N , p ) ,
    logit(p) <- a[tank] ,
    a[tank] ~ dnorm( 0 , 1.5 )
  ), data=dat , chains=4 , log_lik=TRUE )
```


```{r}
## R code 13.3
m13.2 <- ulam(
  alist(
    S ~ dbinom( N , p ) ,
    logit(p) <- a[tank] ,
    a[tank] ~ dnorm( a_bar , sigma ) ,
    a_bar ~ dnorm( 0 , 1.5 ) ,
    sigma ~ dexp( 1 )
  ), data=dat , chains=4 , log_lik=TRUE )
```


```{r}
## R code 13.4
compare( m13.1 , m13.2 )
```


```{r}
## R code 13.5
# extract Stan samples
post <- extract.samples(m13.2)

# compute median intercept for each tank
# also transform to probability with logistic
d$propsurv.est <- logistic( apply( post$a , 2 , mean ) )

# display raw proportions surviving in each tank
plot( d$propsurv , ylim=c(0,1) , pch=16 , xaxt="n" ,
      xlab="tank" , ylab="proportion survival" , col=rangi2 )
axis( 1 , at=c(1,16,32,48) , labels=c(1,16,32,48) )

# overlay posterior means
points( d$propsurv.est )

# mark posterior mean probability across tanks
abline( h=mean(inv_logit(post$a_bar)) , lty=2 )

# draw vertical dividers between tank densities
abline( v=16.5 , lwd=0.5 )
abline( v=32.5 , lwd=0.5 )
text( 8 , 0 , "small tanks" )
text( 16+8 , 0 , "medium tanks" )
text( 32+8 , 0 , "large tanks" )
```


```{r}
## R code 13.6
# show first 100 populations in the posterior
plot( NULL , xlim=c(-3,4) , ylim=c(0,0.35) ,
      xlab="log-odds survive" , ylab="Density" )
for ( i in 1:100 )
  curve( dnorm(x,post$a_bar[i],post$sigma[i]) , add=TRUE ,
         col=col.alpha("black",0.2) )

# sample 8000 imaginary tanks from the posterior distribution
sim_tanks <- rnorm( 8000 , post$a_bar , post$sigma )

# transform to probability and visualize
dens( inv_logit(sim_tanks) , lwd=2 , adj=0.1 )
```


```{r}
## R code 13.7
a_bar <- 1.5
sigma <- 1.5
nponds <- 60
Ni <- as.integer( rep( c(5,10,25,35) , each=15 ) )

## R code 13.8
set.seed(5005)
a_pond <- rnorm( nponds , mean=a_bar , sd=sigma )

## R code 13.9
dsim <- data.frame( pond=1:nponds , Ni=Ni , true_a=a_pond )
dsim
```


```{r}
## R code 13.10
class(1:3)
class(c(1,2,3))

## R code 13.11
dsim$Si <- rbinom( nponds , prob=logistic(dsim$true_a) , size=dsim$Ni )

## R code 13.12
dsim$p_nopool <- dsim$Si / dsim$Ni
dsim
```


```{r}
## R code 13.13
dat <- list( Si=dsim$Si , Ni=dsim$Ni , pond=dsim$pond )
m13.3 <- ulam(
  alist(
    Si ~ dbinom( Ni , p ),
    logit(p) <- a_pond[pond],
    a_pond[pond] ~ dnorm( a_bar , sigma ),
    a_bar ~ dnorm( 0 , 1.5 ),
    sigma ~ dexp( 1 )
  ), data=dat , chains=4 )
```


```{r}
## R code 13.14
precis( m13.3 , depth=2 )
```


```{r}
## R code 13.15
post <- extract.samples( m13.3 )
dsim$p_partpool <- apply( inv_logit(post$a_pond) , 2 , mean )

## R code 13.16
dsim$p_true <- inv_logit( dsim$true_a )

## R code 13.17
nopool_error <- abs( dsim$p_nopool - dsim$p_true )
partpool_error <- abs( dsim$p_partpool - dsim$p_true )

## R code 13.18
plot( 1:60 , nopool_error , xlab="pond" , ylab="absolute error" ,
      col=rangi2 , pch=16 )
points( 1:60 , partpool_error )

## R code 13.19
nopool_avg <- aggregate(nopool_error,list(dsim$Ni),mean)
partpool_avg <- aggregate(partpool_error,list(dsim$Ni),mean)
```


```{r}


## R code 13.20
a <- 1.5
sigma <- 1.5
nponds <- 60
Ni <- as.integer( rep( c(5,10,25,35) , each=15 ) )
a_pond <- rnorm( nponds , mean=a , sd=sigma )
dsim <- data.frame( pond=1:nponds , Ni=Ni , true_a=a_pond )
dsim$Si <- rbinom( nponds,prob=inv_logit( dsim$true_a ),size=dsim$Ni )
dsim$p_nopool <- dsim$Si / dsim$Ni
newdat <- list(Si=dsim$Si,Ni=dsim$Ni,pond=1:nponds)
m13.3new <- stan( fit=m13.3@stanfit , data=newdat , chains=4 )

post <- extract.samples( m13.3new )
dsim$p_partpool <- apply( inv_logit(post$a_pond) , 2 , mean )
dsim$p_true <- inv_logit( dsim$true_a )
nopool_error <- abs( dsim$p_nopool - dsim$p_true )
partpool_error <- abs( dsim$p_partpool - dsim$p_true )
plot( 1:60 , nopool_error , xlab="pond" , ylab="absolute error" , col=rangi2 , pch=16 )
points( 1:60 , partpool_error )

## R code 13.21
library(rethinking)
data(chimpanzees)
d <- chimpanzees
d$treatment <- 1 + d$prosoc_left + 2*d$condition

dat_list <- list(
  pulled_left = d$pulled_left,
  actor = d$actor,
  block_id = d$block,
  treatment = as.integer(d$treatment) )

set.seed(13)
m13.4 <- ulam(
  alist(
    pulled_left ~ dbinom( 1 , p ) ,
    logit(p) <- a[actor] + g[block_id] + b[treatment] ,
    b[treatment] ~ dnorm( 0 , 0.5 ),
    # adaptive priors
    a[actor] ~ dnorm( a_bar , sigma_a ),
    g[block_id] ~ dnorm( 0 , sigma_g ),
    # hyper-priors
    a_bar ~ dnorm( 0 , 1.5 ),
    sigma_a ~ dexp(1),
    sigma_g ~ dexp(1)
  ) , data=dat_list , chains=4 , cores=4 , log_lik=TRUE )

## R code 13.22
precis( m13.4 , depth=2 )
plot( precis(m13.4,depth=2) ) # also plot

## R code 13.23
set.seed(14)
m13.5 <- ulam(
  alist(
    pulled_left ~ dbinom( 1 , p ) ,
    logit(p) <- a[actor] + b[treatment] ,
    b[treatment] ~ dnorm( 0 , 0.5 ),
    a[actor] ~ dnorm( a_bar , sigma_a ),
    a_bar ~ dnorm( 0 , 1.5 ),
    sigma_a ~ dexp(1)
  ) , data=dat_list , chains=4 , cores=4 , log_lik=TRUE )

## R code 13.24
compare( m13.4 , m13.5 )

## R code 13.25
set.seed(15)
m13.6 <- ulam(
  alist(
    pulled_left ~ dbinom( 1 , p ) ,
    logit(p) <- a[actor] + g[block_id] + b[treatment] ,
    b[treatment] ~ dnorm( 0 , sigma_b ),
    a[actor] ~ dnorm( a_bar , sigma_a ),
    g[block_id] ~ dnorm( 0 , sigma_g ),
    a_bar ~ dnorm( 0 , 1.5 ),
    sigma_a ~ dexp(1),
    sigma_g ~ dexp(1),
    sigma_b ~ dexp(1)
  ) , data=dat_list , chains=4 , cores=4 , log_lik=TRUE )
coeftab(m13.4,m13.6)

## R code 13.26
m13x <- ulam(
  alist(
    v ~ normal(0,3),
    x ~ normal(0,exp(v))
  ), data=list(N=1) , chains=4 )
precis(m13x)

## R code 13.27
m13y <- ulam(
  alist(
    v ~ normal(0,3),
    z ~ normal(0,1),
    gq> real[1]:x <<- z*exp(v)
  ), data=list(N=1) , chains=4 )
precis(m13y)

## R code 13.28
set.seed(13)
m13.4b <- ulam( m13.4 , chains=4 , cores=4 , control=list(adapt_delta=0.99) )
divergent(m13.4b)

## R code 13.29
set.seed(13)
m13.4nc <- ulam(
  alist(
    pulled_left ~ dbinom( 1 , p ) ,
    logit(p) <- a_bar + z[actor]*sigma_a + # actor intercepts
      x[block_id]*sigma_g +      # block intercepts
      b[treatment] ,
    b[treatment] ~ dnorm( 0 , 0.5 ),
    z[actor] ~ dnorm( 0 , 1 ),
    x[block_id] ~ dnorm( 0 , 1 ),
    a_bar ~ dnorm( 0 , 1.5 ),
    sigma_a ~ dexp(1),
    sigma_g ~ dexp(1)
  ) , data=dat_list , chains=4 , cores=4 )

## R code 13.30
neff_c <- precis( m13.4 , depth=2 )[['n_eff']]
neff_nc <- precis( m13.4nc , depth=2 )[['n_eff']]
par_names <- rownames( precis( m13.4 , depth=2 ) )
neff_table <- cbind( neff_c , neff_nc )
rownames(neff_table) <- par_names
round(t(neff_table))

## R code 13.31
chimp <- 2
d_pred <- list(
  actor = rep(chimp,4),
  treatment = 1:4,
  block_id = rep(1,4)
)
p <- link( m13.4 , data=d_pred )
p_mu <- apply( p , 2 , mean )
p_ci <- apply( p , 2 , PI )

## R code 13.32
post <- extract.samples(m13.4)
str(post)

## R code 13.33
dens( post$a[,5] )

## R code 13.34
p_link <- function( treatment , actor=1 , block_id=1 ) {
  logodds <- with( post ,
                   a[,actor] + g[,block_id] + b[,treatment] )
  return( inv_logit(logodds) )
}

## R code 13.35
p_raw <- sapply( 1:4 , function(i) p_link( i , actor=2 , block_id=1 ) )
p_mu <- apply( p_raw , 2 , mean )
p_ci <- apply( p_raw , 2 , PI )

## R code 13.36
p_link_abar <- function( treatment ) {
  logodds <- with( post , a_bar + b[,treatment] )
  return( inv_logit(logodds) )
}

## R code 13.37
p_raw <- sapply( 1:4 , function(i) p_link_abar( i ) )
p_mu <- apply( p_raw , 2 , mean )
p_ci <- apply( p_raw , 2 , PI )

plot( NULL , xlab="treatment" , ylab="proportion pulled left" ,
      ylim=c(0,1) , xaxt="n" , xlim=c(1,4) )
axis( 1 , at=1:4 , labels=c("R/N","L/N","R/P","L/P") )
lines( 1:4 , p_mu )
shade( p_ci , 1:4 )

## R code 13.38
a_sim <- with( post , rnorm( length(post$a_bar) , a_bar , sigma_a ) )
p_link_asim <- function( treatment ) {
  logodds <- with( post , a_sim + b[,treatment] )
  return( inv_logit(logodds) )
}
p_raw_asim <- sapply( 1:4 , function(i) p_link_asim( i ) )

## R code 13.39
plot( NULL , xlab="treatment" , ylab="proportion pulled left" ,
      ylim=c(0,1) , xaxt="n" , xlim=c(1,4) )
axis( 1 , at=1:4 , labels=c("R/N","L/N","R/P","L/P") )
for ( i in 1:100 ) lines( 1:4 , p_raw_asim[i,] , col=col.alpha("black",0.25) , lwd=2 )

## R code 13.40
sort(unique(d$district))

## R code 13.41
d$district_id <- as.integer(as.factor(d$district))
sort(unique(d$district_id))

```

